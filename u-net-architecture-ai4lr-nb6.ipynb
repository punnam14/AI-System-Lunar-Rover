{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <center>(AI4LR) - Notebook 6 [Final]\n    \nTotal Points: 100\n\nThis notebook is designed to get you fimiliar with the U-Net architecture. (and choosing a backbone)","metadata":{"id":"xksEYwr8QXgN"}},{"cell_type":"markdown","source":"### **NOTE: Open this notebook in kaggle and import Artificial Lunar Landscape Dataset.** ","metadata":{"id":"_qWKqzF4415S"}},{"cell_type":"markdown","source":"## > If you run this notebook as it is, you will get the val_iou_score of around 0.20 (remember to use GPU for training the model)\n\n## > Your goal is to increase the val_iou_score as much as you can for this project using any method. The evaluation of this assignment will be based on your acquired val_iou_score. One point for each increasing 0.01 val_iou_score. \n\n> For example - if val_iou_score = 0.41, your points will be 41/100. \n\n### Some tips to increase the performance\n* Increase the number of epochs\n* Increase the number of layers in your model\n* Using SOTA high performance networks with transfer learning\n* Using callbacks and carefully observing your model performance\n\nYou are free to use other techniques too. ","metadata":{"id":"rb3HM3Asm8y1"}},{"cell_type":"code","source":"!pip install segmentation_models","metadata":{"id":"HRJUKjN1QXgS","execution":{"iopub.status.busy":"2022-04-17T13:46:13.165301Z","iopub.execute_input":"2022-04-17T13:46:13.165697Z","iopub.status.idle":"2022-04-17T13:46:27.212326Z","shell.execute_reply.started":"2022-04-17T13:46:13.165602Z","shell.execute_reply":"2022-04-17T13:46:27.211263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nimport cv2\nimport keras\nfrom tqdm import tqdm\n\nimport tensorflow as tf\nimport glob\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\n\nfrom skimage.io import imread\nfrom skimage.transform import resize\nimport numpy as np\nimport math\nfrom tensorflow.keras.utils import to_categorical, Sequence\n\nimport segmentation_models as sm\n\nimport datetime","metadata":{"id":"bGIcq3_DQXgT","execution":{"iopub.status.busy":"2022-04-17T13:46:28.440718Z","iopub.execute_input":"2022-04-17T13:46:28.441058Z","iopub.status.idle":"2022-04-17T13:46:36.263325Z","shell.execute_reply.started":"2022-04-17T13:46:28.441025Z","shell.execute_reply":"2022-04-17T13:46:36.262287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Provide environment variable SM_FRAMEWORK=keras / SM_FRAMEWORK=tf.keras before import segmentation_models\n* Change framework sm.set_framework('keras') / sm.set_framework('tf.keras')","metadata":{"id":"TIJMgWvKm8y7"}},{"cell_type":"code","source":"os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\nsm.set_framework('tf.keras')\nkeras.backend.set_image_data_format('channels_last')","metadata":{"id":"x2HKIVofm8y7","execution":{"iopub.status.busy":"2022-04-17T13:46:41.241311Z","iopub.execute_input":"2022-04-17T13:46:41.241760Z","iopub.status.idle":"2022-04-17T13:46:41.250924Z","shell.execute_reply.started":"2022-04-17T13:46:41.241695Z","shell.execute_reply":"2022-04-17T13:46:41.249664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing Pipeline ","metadata":{}},{"cell_type":"code","source":"H = 256 # height of image\nW = 256 # width of image\n\n'''This function is used to return the list of path for images and masks in\nsorted order from the given directory respectively.'''\n# function to return list of image paths and mask paths \ndef process_data(IMG_DIR, MASK_DIR):\n    images = [os.path.join(IMG_DIR, x) for x in sorted(os.listdir(IMG_DIR))]\n    masks = [os.path.join(MASK_DIR, x) for x in sorted(os.listdir(MASK_DIR))]\n\n    return images, masks\n\n'''This function is used to return splitted list of images and corresponding \nmask paths in train and test by providing test size.'''\n# function to load data and train test split\ndef load_data(IMG_DIR, MASK_DIR):\n    X, y = process_data(IMG_DIR, MASK_DIR)\n    \n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42)\n     \n    return X_train, X_test, y_train, y_test\n\n'''This function is used to read images. It takes image path as input. \nAfter reading image it is resized by width and height provide above(256 x 256). \nNext normalization is done by dividing each values with 255. And the result is returned.'''\n# function to read image\ndef read_image(x):\n    x = cv2.imread(x, cv2.IMREAD_COLOR)\n    x = cv2.resize(x, (W, H))\n    x = x / 255.0\n    x = x.astype(np.float32)\n    return x\n\n'''This function is used to read masks.'''\n# function to read mask\ndef read_mask(x):\n    x = cv2.imread(x, cv2.IMREAD_GRAYSCALE)\n    x = cv2.resize(x, (W, H))\n    x = x.astype(np.int32)\n    return x\n\n'''This function is used to generate tensorflow data pipeline. \nThe tensorflow data pipeline is mapped to function ‘preprocess’ .'''\n# function for tensorflow dataset pipeline\ndef tf_dataset(x, y, batch=8):\n    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n    dataset = dataset.shuffle(buffer_size=5000)\n    dataset = dataset.map(preprocess)\n    dataset = dataset.batch(batch)\n    dataset = dataset.repeat()\n    dataset = dataset.prefetch(2)\n     return dataset\n\n'''This function takes image and mask path. \nIt reads the image and mask as provided by paths. \nMask is one hot encoded for multi class segmentation (here 4 class).'''\n# function to read image and mask amd create one hot encoding for mask\ndef preprocess(x, y):\n    def f(x, y):\n        x = x.decode()\n        y = y.decode()\n\n        image = read_image(x)\n        mask = read_mask(y)\n\n        return image, mask\n\n    image, mask = tf.numpy_function(f, [x, y], [tf.float32, tf.int32])\n    mask = tf.one_hot(mask, 4, dtype=tf.int32)\n    image.set_shape([H, W, 3])\n    mask.set_shape([H, W, 4])\n\n    return image, mask","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load the dataset","metadata":{}},{"cell_type":"code","source":"'''RENDER_IMAGE_DIR_PATH: ‘Path of image directory’\nGROUND_MASK_DIR_PATH: ‘Path of mask directory’\n\nHere load_data function is called. This will load the dataset paths and \nsplit it into X_train, X_test, y_train, y_test '''\n\nRENDER_IMAGE_DIR_PATH = '../input/artificial-lunar-rocky-landscape-dataset/images/render'\nGROUND_MASK_DIR_PATH = '../input/artificial-lunar-rocky-landscape-dataset/images/clean'\n\nX_train, X_test, y_train, y_test = load_data(RENDER_IMAGE_DIR_PATH, GROUND_MASK_DIR_PATH)\nprint(f\"Dataset:\\n Train: {len(X_train)} \\n Test: {len(X_test)}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Generate tensorflow data pipeline","metadata":{}},{"cell_type":"code","source":"batch_size = 8\n\n'''Here the tf_dataset function is called will generate the tensorflow data pipeline.'''\n# calling tf_dataset\ntrain_dataset = tf_dataset(X_train, y_train, batch=batch_size)\nvalid_dataset = tf_dataset(X_test, y_test, batch=batch_size)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating U-net Architecture","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPool2D, UpSampling2D, Concatenate\nfrom tensorflow.keras.models import Model\n\n'''conv_block it is used to create one block with two convolution layer \nfollowed by BatchNormalization and activation function relu. \nIf the pooling is required then Maxpool2D is applied and return it else not.'''\n# function to create convolution block\ndef conv_block(inputs, filters, pool=True):\n    x = Conv2D(filters, 3, padding=\"same\")(inputs)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n\n    x = Conv2D(filters, 3, padding=\"same\")(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n\n    if pool == True:\n        p = MaxPool2D((2, 2))(x)\n        return x, p\n    else:\n        return x\n\n'''build_unet it is used to create the U-net architecture.'''\n# function to build U-net\ndef build_unet(shape, num_classes):\n    inputs = Input(shape)\n\n    \"\"\" Encoder \"\"\"\n    x1, p1 = conv_block(inputs, 16, pool=True)\n    x2, p2 = conv_block(p1, 32, pool=True)\n    x3, p3 = conv_block(p2, 48, pool=True)\n    x4, p4 = conv_block(p3, 64, pool=True)\n    \n     \"\"\" Bridge \"\"\"\n    b1 = conv_block(p4, 128, pool=False)\n\n    \"\"\" Decoder \"\"\"\n    u1 = UpSampling2D((2, 2), interpolation=\"bilinear\")(b1)\n    c1 = Concatenate()([u1, x4])\n    x5 = conv_block(c1, 64, pool=False)\n\n    u2 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x5)\n    c2 = Concatenate()([u2, x3])\n    x6 = conv_block(c2, 48, pool=False)\n\n    u3 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x6)\n    c3 = Concatenate()([u3, x2])\n    x7 = conv_block(c3, 32, pool=False)\n\n    u4 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x7)\n    c4 = Concatenate()([u4, x1])\n    x8 = conv_block(c4, 16, pool=False)\n\n    \"\"\" Output layer \"\"\"\n    output = Conv2D(num_classes, 1, padding=\"same\", activation=\"softmax\")(x8)\n\n    return Model(inputs, output)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calling build_unet function\nmodel = build_unet((256, 256, 3), 4)\nmodel.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load model and compile","metadata":{}},{"cell_type":"code","source":"# importing libraries\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\nfrom segmentation_models.metrics import iou_score\nimport datetime, os\n\n\"\"\" Hyperparameters \"\"\"\nimg_shape = (256, 256, 3)\nnum_classes = 4\nlr = 1e-4\nbatch_size = 16\nepochs = 5\n\n\"\"\" Model \"\"\"\nmodel = build_unet(img_shape, num_classes)\nmodel.compile(loss=\"categorical_crossentropy\", \n              optimizer=tf.keras.optimizers.Adam(lr), \n              metrics=[iou_score])\n\n\ntrain_steps = len(X_train)//batch_size\nvalid_steps = len(X_test)//batch_size","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train model ","metadata":{}},{"cell_type":"code","source":"'''model.fit is used to train the model'''\nmodel_history = model.fit(train_dataset,\n        steps_per_epoch=train_steps,\n        validation_data=valid_dataset,\n        validation_steps=valid_steps,\n        epochs=epochs,\n    )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Improved Method","metadata":{}},{"cell_type":"markdown","source":"## Data Preprocessing Pipeline","metadata":{"id":"OdS9NTtwQXgV"}},{"cell_type":"code","source":"img_dir = '../input/artificial-lunar-rocky-landscape-dataset/images/render'\nmask_dir = '../input/artificial-lunar-rocky-landscape-dataset/images/clean'\n\nimages = [os.path.join(img_dir, x) for x in sorted(os.listdir(img_dir))]\nmasks = [os.path.join(mask_dir, x) for x in sorted(os.listdir(mask_dir))]\n\nX_train = images[:8000]\ny_train = masks[:8000]\n\nX_valid = images[8000:]\ny_valid = masks[8000:]","metadata":{"id":"EQGsLbOVQXgW","execution":{"iopub.status.busy":"2022-04-17T13:47:06.301736Z","iopub.execute_input":"2022-04-17T13:47:06.302038Z","iopub.status.idle":"2022-04-17T13:47:06.766459Z","shell.execute_reply.started":"2022-04-17T13:47:06.302005Z","shell.execute_reply":"2022-04-17T13:47:06.765485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load the dataset","metadata":{"id":"ufOlyg7MQXgY"}},{"cell_type":"code","source":"class LunarDataset(Sequence):\n\n    def __init__(self, x_set, y_set, batch_size):\n        self.x, self.y = x_set, y_set\n        self.batch_size = batch_size\n\n    def __len__(self):\n        return math.ceil(len(self.x) / self.batch_size)\n\n    def __getitem__(self, idx):\n        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n        \n        count = 0\n        xtr = np.zeros((16, 480, 480, 3))\n        for filename in batch_x:\n            img = imread(filename)[:480, :480, :] / 255.0\n            img = img.astype(np.float32)\n            xtr[count] = img\n            count += 1\n            \n        count = 0\n        ytr = np.zeros((16, 480, 480, 4))\n        for filename in batch_y:\n            mask = imread(filename, as_gray = True)[:480, :480] // 0.07\n            mask[mask == 3] = 2\n            mask[mask == 10] = 3\n         \n            mask = to_categorical(mask, num_classes = 4)\n            ytr[count] = mask\n            count += 1\n\n        return xtr, ytr.astype(np.int32)\n\ntrain_dataset = LunarDataset(X_train, y_train, 16)\nvalid_dataset = LunarDataset(X_valid, y_valid, 16)","metadata":{"id":"vHWstFNTQXgY","execution":{"iopub.status.busy":"2022-04-17T13:47:12.913224Z","iopub.execute_input":"2022-04-17T13:47:12.913499Z","iopub.status.idle":"2022-04-17T13:47:12.926004Z","shell.execute_reply.started":"2022-04-17T13:47:12.913470Z","shell.execute_reply":"2022-04-17T13:47:12.925042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Generate tensorflow data pipeline","metadata":{"id":"WfSTVsjCQXgZ"}},{"cell_type":"code","source":"IMG_SHAPE = (480, 480, 3)\n\nbase_model = tf.keras.applications.InceptionV3(input_shape=IMG_SHAPE,\n                                               include_top=False,\n                                               weights='imagenet')\n\nbase_model.trainable = False\n\nbase_model.summary()\n\ninputs = tf.keras.Input(shape=(480, 480, 3))\n\nx = base_model(inputs, training=False)\n\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\nx = tf.keras.layers.Dropout(0.2)(x)\noutputs = tf.keras.layers.Dense(2)(x)\n\nmodel = tf.keras.Model(inputs, outputs)\n\nmodel.summary()","metadata":{"id":"4xsJKtW0QXgZ","execution":{"iopub.status.busy":"2022-04-17T13:47:17.661235Z","iopub.execute_input":"2022-04-17T13:47:17.661544Z","iopub.status.idle":"2022-04-17T13:47:25.324268Z","shell.execute_reply.started":"2022-04-17T13:47:17.661497Z","shell.execute_reply":"2022-04-17T13:47:25.323112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating U-net Architecture","metadata":{"id":"1MqxtDTmQXga"}},{"cell_type":"code","source":"BACKBONE = 'vgg16'\ninput_shape = (480, 480, 3)\nn_classes = 4\nactivation = 'softmax'\n\nmodel = sm.Unet(backbone_name = BACKBONE, \n                input_shape = input_shape, \n                classes = n_classes, \n                activation = activation,\n                encoder_weights = 'imagenet')\nmodel.summary()","metadata":{"id":"tYCyf8smQXga","execution":{"iopub.status.busy":"2022-04-17T13:47:39.793027Z","iopub.execute_input":"2022-04-17T13:47:39.793328Z","iopub.status.idle":"2022-04-17T13:47:43.122285Z","shell.execute_reply.started":"2022-04-17T13:47:39.793281Z","shell.execute_reply":"2022-04-17T13:47:43.121300Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load model and compile","metadata":{"id":"bMgeqmX2QXgc"}},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint\nlr = 1e-4\nbatch_size = 16\nepochs = 17\n\nmetrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n\nmodel.compile(loss = 'categorical_crossentropy', \n              optimizer = tf.keras.optimizers.Adam(lr), \n              metrics = metrics)\n\ntrain_steps = len(X_train)//batch_size\nvalid_steps = len(X_valid)//batch_size\n\ncurrent_datetime = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n\ncallbacks = [\n        tf.keras.callbacks.ModelCheckpoint(filepath=f'models/lunarModel_{current_datetime}.h5',\n                        monitor='val_iou_score', verbose=0, \n                        mode='max', save_best_model=True),\n             \n        tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_iou_score\", mode='max', patience=4,\n                          factor=0.1, verbose=0, min_lr=1e-6),\n             \n        tf.keras.callbacks.EarlyStopping(monitor=\"val_iou_score\", patience=5, verbose=0, mode='max'),\n\n        tf.keras.callbacks.TensorBoard(f'models/logs_{current_datetime}')\n    ]","metadata":{"id":"z91qV2ZwQXgc","execution":{"iopub.status.busy":"2022-04-17T13:47:49.480240Z","iopub.execute_input":"2022-04-17T13:47:49.480519Z","iopub.status.idle":"2022-04-17T13:47:49.831843Z","shell.execute_reply.started":"2022-04-17T13:47:49.480490Z","shell.execute_reply":"2022-04-17T13:47:49.830286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train model","metadata":{"id":"SBhRPBKPQXgc"}},{"cell_type":"code","source":"model_history = model.fit(train_dataset,\n        steps_per_epoch=train_steps,\n        validation_data=valid_dataset,\n        validation_steps=valid_steps,\n        epochs=epochs,\n        callbacks=callbacks\n    )","metadata":{"id":"4lJgBNVwQXgd","execution":{"iopub.status.busy":"2022-04-17T13:47:55.663633Z","iopub.execute_input":"2022-04-17T13:47:55.664253Z","iopub.status.idle":"2022-04-17T16:25:45.581368Z","shell.execute_reply.started":"2022-04-17T13:47:55.664219Z","shell.execute_reply":"2022-04-17T16:25:45.580381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## [IMPORTANT] final model training history \nNOTE: If we find that your actual model score and what you paste here is differing, your assignment will get rejected.  \n\nhere ----\n\nResults with VGG16 - 17 Epochs\n\nEpoch 1/17\n  1/500 [..............................] - ETA: 3:08:29 - loss: 1.6735 - iou_score: 0.0323 - f1-score: 0.0618\n  2/500 [..............................] - ETA: 9:07 - loss: 1.6341 - iou_score: 0.0326 - f1-score: 0.0624   \n500/500 [==============================] - 760s 1s/step - loss: 0.3566 - iou_score: 0.5339 - f1-score: 0.6016 - val_loss: 0.1722 - val_iou_score: 0.6035 - val_f1-score: 0.6817\nEpoch 2/17\n500/500 [==============================] - 626s 1s/step - loss: 0.1398 - iou_score: 0.7121 - f1-score: 0.8005 - val_loss: 0.1349 - val_iou_score: 0.6683 - val_f1-score: 0.7495\nEpoch 3/17\n500/500 [==============================] - 622s 1s/step - loss: 0.1150 - iou_score: 0.7542 - f1-score: 0.8385 - val_loss: 0.1111 - val_iou_score: 0.7470 - val_f1-score: 0.8320\nEpoch 4/17\n500/500 [==============================] - 624s 1s/step - loss: 0.1035 - iou_score: 0.7781 - f1-score: 0.8580 - val_loss: 0.0971 - val_iou_score: 0.7954 - val_f1-score: 0.8718\nEpoch 5/17\n500/500 [==============================] - 627s 1s/step - loss: 0.0967 - iou_score: 0.7913 - f1-score: 0.8681 - val_loss: 0.0895 - val_iou_score: 0.8057 - val_f1-score: 0.8793\nEpoch 6/17\n500/500 [==============================] - 589s 1s/step - loss: 0.0911 - iou_score: 0.8057 - f1-score: 0.8792 - val_loss: 0.0979 - val_iou_score: 0.7851 - val_f1-score: 0.8632\nEpoch 7/17\n500/500 [==============================] - 565s 1s/step - loss: 0.0884 - iou_score: 0.8094 - f1-score: 0.8821 - val_loss: 0.0919 - val_iou_score: 0.8000 - val_f1-score: 0.8754\nEpoch 8/17\n500/500 [==============================] - 621s 1s/step - loss: 0.0860 - iou_score: 0.8134 - f1-score: 0.8851 - val_loss: 0.0847 - val_iou_score: 0.8174 - val_f1-score: 0.8875\nEpoch 9/17\n500/500 [==============================] - 572s 1s/step - loss: 0.0826 - iou_score: 0.8225 - f1-score: 0.8918 - val_loss: 0.0844 - val_iou_score: 0.8146 - val_f1-score: 0.8854\nEpoch 10/17\n500/500 [==============================] - 572s 1s/step - loss: 0.0779 - iou_score: 0.8334 - f1-score: 0.8997 - val_loss: 0.0947 - val_iou_score: 0.7923 - val_f1-score: 0.8692\nEpoch 11/17\n500/500 [==============================] - 571s 1s/step - loss: 0.0787 - iou_score: 0.8286 - f1-score: 0.8961 - val_loss: 0.0933 - val_iou_score: 0.7920 - val_f1-score: 0.8677\nEpoch 12/17\n500/500 [==============================] - 626s 1s/step - loss: 0.0774 - iou_score: 0.8325 - f1-score: 0.8988 - val_loss: 0.0936 - val_iou_score: 0.7866 - val_f1-score: 0.8642\nEpoch 13/17\n500/500 [==============================] - 573s 1s/step - loss: 0.0661 - iou_score: 0.8567 - f1-score: 0.9160 - val_loss: 0.0777 - val_iou_score: 0.8356 - val_f1-score: 0.9007\nEpoch 14/17\n500/500 [==============================] - 627s 1s/step - loss: 0.0637 - iou_score: 0.8601 - f1-score: 0.9183 - val_loss: 0.0778 - val_iou_score: 0.8375 - val_f1-score: 0.9021\nEpoch 15/17\n500/500 [==============================] - 573s 1s/step - loss: 0.0622 - iou_score: 0.8614 - f1-score: 0.9191 - val_loss: 0.0781 - val_iou_score: 0.8387 - val_f1-score: 0.9029\nEpoch 16/17\n500/500 [==============================] - 629s 1s/step - loss: 0.0608 - iou_score: 0.8628 - f1-score: 0.9200 - val_loss: 0.0786 - val_iou_score: 0.8387 - val_f1-score: 0.9030\nEpoch 17/17\n500/500 [==============================] - 542s 1s/step - loss: 0.0592 - iou_score: 0.8642 - f1-score: 0.9210 - val_loss: 0.0792 - val_iou_score: 0.8348 - val_f1-score: 0.9002\n\n\n\n\n\n\n\n\n\n\nResults with InceptionV3 - 17 Epochs\n\n\nEpoch 1/17\n  1/500 [..............................] - ETA: 3:07:30 - loss: 1.4688 - iou_score: 0.0228 - f1-score: 0.0440\n  2/500 [..............................] - ETA: 8:56 - loss: 1.4301 - iou_score: 0.0221 - f1-score: 0.0428 \n500/500 [==============================] - 672s 1s/step - loss: 0.3617 - iou_score: 0.4389 - f1-score: 0.4633 - val_loss: 0.1881 - val_iou_score: 0.5016 - val_f1-score: 0.5300\nEpoch 2/17\n500/500 [==============================] - 537s 1s/step - loss: 0.1563 - iou_score: 0.5796 - f1-score: 0.6418 - val_loss: 0.1390 - val_iou_score: 0.6709 - val_f1-score: 0.7595\nEpoch 3/17\n500/500 [==============================] - 536s 1s/step - loss: 0.1170 - iou_score: 0.7403 - f1-score: 0.8260 - val_loss: 0.1061 - val_iou_score: 0.7429 - val_f1-score: 0.8277\nEpoch 4/17\n500/500 [==============================] - 533s 1s/step - loss: 0.1054 - iou_score: 0.7699 - f1-score: 0.8514 - val_loss: 0.0963 - val_iou_score: 0.7836 - val_f1-score: 0.8620\nEpoch 5/17\n500/500 [==============================] - 597s 1s/step - loss: 0.0972 - iou_score: 0.7885 - f1-score: 0.8663 - val_loss: 0.0926 - val_iou_score: 0.7918 - val_f1-score: 0.8683\nEpoch 6/17\n500/500 [==============================] - 510s 1s/step - loss: 0.0929 - iou_score: 0.7985 - f1-score: 0.8736 - val_loss: 0.0857 - val_iou_score: 0.8097 - val_f1-score: 0.8823\nEpoch 7/17\n500/500 [==============================] - 536s 1s/step - loss: 0.0874 - iou_score: 0.8114 - f1-score: 0.8838 - val_loss: 0.1270 - val_iou_score: 0.7359 - val_f1-score: 0.8186\nEpoch 8/17\n500/500 [==============================] - 539s 1s/step - loss: 0.0848 - iou_score: 0.8175 - f1-score: 0.8882 - val_loss: 0.0888 - val_iou_score: 0.8083 - val_f1-score: 0.8808\nEpoch 9/17\n500/500 [==============================] - 535s 1s/step - loss: 0.0816 - iou_score: 0.8238 - f1-score: 0.8927 - val_loss: 0.1555 - val_iou_score: 0.7029 - val_f1-score: 0.7875\nEpoch 10/17\n500/500 [==============================] - 533s 1s/step - loss: 0.0806 - iou_score: 0.8266 - f1-score: 0.8948 - val_loss: 0.0955 - val_iou_score: 0.7862 - val_f1-score: 0.8637\nEpoch 11/17\n500/500 [==============================] - 596s 1s/step - loss: 0.0721 - iou_score: 0.8444 - f1-score: 0.9076 - val_loss: 0.0795 - val_iou_score: 0.8269 - val_f1-score: 0.8947\nEpoch 12/17\n500/500 [==============================] - 536s 1s/step - loss: 0.0684 - iou_score: 0.8516 - f1-score: 0.9126 - val_loss: 0.0790 - val_iou_score: 0.8297 - val_f1-score: 0.8966\nEpoch 13/17\n500/500 [==============================] - 534s 1s/step - loss: 0.0669 - iou_score: 0.8545 - f1-score: 0.9145 - val_loss: 0.0791 - val_iou_score: 0.8322 - val_f1-score: 0.8985\nEpoch 14/17\n500/500 [==============================] - 509s 1s/step - loss: 0.0655 - iou_score: 0.8565 - f1-score: 0.9159 - val_loss: 0.0788 - val_iou_score: 0.8315 - val_f1-score: 0.8980\nEpoch 15/17\n500/500 [==============================] - 530s 1s/step - loss: 0.0640 - iou_score: 0.8579 - f1-score: 0.9168 - val_loss: 0.0787 - val_iou_score: 0.8306 - val_f1-score: 0.8973\nEpoch 16/17\n500/500 [==============================] - 599s 1s/step - loss: 0.0629 - iou_score: 0.8596 - f1-score: 0.9179 - val_loss: 0.0804 - val_iou_score: 0.8314 - val_f1-score: 0.8979\nEpoch 17/17\n500/500 [==============================] - 599s 1s/step - loss: 0.0615 - iou_score: 0.8609 - f1-score: 0.9188 - val_loss: 0.0800 - val_iou_score: 0.8320 - val_f1-score: 0.8982","metadata":{"id":"I1OFxBbnxC_I"}}]}