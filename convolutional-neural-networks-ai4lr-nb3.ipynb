{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <center> (AI4LR) - Notebook 4\n\nTotal Points: 50\n\nThis notebook is designed to get you fimiliar with convolutional neural netoworks.","metadata":{"id":"IZUj9ctCef14"}},{"cell_type":"code","source":"## Import necessary libraries\n\nimport numpy as np\nimport tensorflow as tf","metadata":{"id":"WUhtO_uo0o3t","execution":{"iopub.status.busy":"2022-03-27T08:51:33.677531Z","iopub.execute_input":"2022-03-27T08:51:33.678238Z","iopub.status.idle":"2022-03-27T08:51:39.513514Z","shell.execute_reply.started":"2022-03-27T08:51:33.678099Z","shell.execute_reply":"2022-03-27T08:51:39.512440Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Q1 (2 points)\n\nWhich answer explains better the ReLU?\n\n>A. Helps in the detection of features, increasing the non-linearity of the image, converting positive pixels to zero. This behaviour allows you to detect variations of attributes.\n\n>B. It is used to find the best features considering their correlation.\n\n>C. A technique that allows you to find outliers.\n\n>D. Helps in the detection of features, decreasing the non-linearity of the image, converting negative pixels to zero. This behaviour allows you to detect variations of attributes.\n","metadata":{"id":"mI4hjMGsqAVd"}},{"cell_type":"code","source":"# print your answer here\n\nprint(\"D\")","metadata":{"id":"LhyCfvX1qOYu","execution":{"iopub.status.busy":"2022-03-27T08:52:44.631095Z","iopub.execute_input":"2022-03-27T08:52:44.631433Z","iopub.status.idle":"2022-03-27T08:52:44.637619Z","shell.execute_reply.started":"2022-03-27T08:52:44.631401Z","shell.execute_reply":"2022-03-27T08:52:44.636415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Q2 (25 points, 5 points each)\n\nState differences between - (with one example) \n\n> A. Convolution and Pooling\n\n> B. Average pooling and Max Pooling\n\n> C. Padding and strides in convolution\n\n> D. Convolution layer and Dense layer\n\n> E. Sigmoid and ReLU activation function\n","metadata":{"id":"YmUafNEXqfy6"}},{"cell_type":"code","source":"# write your answers here \n\nA = \n\"\"\"The major difference is a convolution filter is extracting features from the matrix of data, whereas the \n    pooling layer is only downsampling the matrix of data.\n    Convolution can be visualised as a filter which takes the neighbouring pixels into consideration. If our \n    filter is 3x3 then we can look at the neigbouring pixels and multiply the value with the the corresponding \n    filter value to get the new pixel value.\n    Pooling is used to reduce the spatial dimension of the activations. If 4x4 is your activation. We can \n    take the max of each of the four 2x2 windows (with a stride of 2) the activation will then reduce from the \n    size of 4x4 to 2x2 after the max-pool operation.\"\"\"\n\n\n\nB = \n\"\"\"Max pooling layer picks maximum values from the convoluted feature maps and Avg pooling layer takes the average\n   value of the features from the feature maps.\n   Max pooling extracts the most important features like edges whereas, average pooling extracts features more smoothly.\n   Max pooling - takes average from the widow , Avg pooling - Averages all values in the window to give one output.\"\"\"\n\n\n\nC = \n\"\"\"Stride denotes how many steps we are moving in each steps in convolution.By default it is one.\n   After convolution we observe that the size of output is smaller that input. To maintain the dimension of output \n   (feature map) same as in input , we use padding. \n   Padding is a process of adding zeros to the input matrix symmetrically.\n   For (n x n) image = (8 x 8)\n       (f x f) filter = (3 x 3)\n       result from convolution (n – f + 1) x (n – f + 1) = (6 x 6)\n       p = number of layers of zeros added to the border of the image\n       (n x n) image becomes (n + 2p) x (n + 2p) image after padding\n       For One layer of padding p = 1\n       applying convolution (with (f x f) filter) outputs (n + 2p – f + 1) x (n + 2p – f + 1) image\n       For an (8 x 8) image and using a (3 x 3) filter with padding p = 1\n       we would get an (8 x 8) output after performing convolution.\"\"\"\n    \n\n\n\nD = \n\"\"\"A densely connected layer provides learning features from all the combinations of the features of the previous \n   layer, whereas a convolutional layer relies on consistent features with a small repetitive field.\n   the main difference between the Convolutional layer and the Dense layer is that Convolutional Layer uses fewer \n   parameters by forcing input values to share the parameters. The Dense Layer uses a linear operation meaning every \n   output is formed by the function based on every input.\"\"\"\n\n\n\nE = \n\"\"\"Range of sigmoid functio is from 0 to 1 whereas range of RELU is from 0 to infinity\n   Sigmoid is non-linear in nature whereas RELU is Linear in nature. \n   Equation of Sigmoid function is S(x)= 1/(1+e^(-x))\n   Equation of RELU is S(x) = 0 for x<0 and x for x>=0\"\"\"","metadata":{"id":"G_gsSMt9tmZl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Q3 (5 points)\n\nWhat will be the output shape of the feature map after following operations on Input shape = (32, 32, 3) \n\n\n\n1. tf.keras.layers.Conv2D(\n    filters = 16,\n    kernel_size = 3,\n    strides=(1, 1),\n    padding=\"valid\",\n    activation=ReLU,\n)\n\n2. tf.keras.layers.MaxPooling2D(\n    pool_size=(2, 2)\n)\n\n3. tf.keras.layers.BatchNormalization()\n\n\n\n","metadata":{"id":"2Ra2DJgxue-S"}},{"cell_type":"code","source":"# print your answer here\n\noutput_shape_conv = (30,30,16)\nprint(\"output shape after CONV 2D is: \", output_shape_conv)\n\"\"\"\nFilter F = 16\ninput W = 32\nkernel size K = 3\npadding P = 0 \nstride S = 1 \nusing [(W−K+2P)/S]+1 = [(32-3+0)/1]+1 = 30\n\"\"\"\noutput_shape_pool = (29,29,16)\nprint(\"output shape after MAX POOLING 2D is: \" ,output_shape_pool)\n\"\"\"\nFilter = 8\ninput W = 30\nkernel size K = 2\npadding P = 0 \nstride S = 1 \nusing [(W−K+2P)/S]+1 = [(30-2+0)/1]+1 = 29\n\"\"\"","metadata":{"id":"V3tWW82Uw2jB","execution":{"iopub.status.busy":"2022-03-27T12:06:34.608401Z","iopub.execute_input":"2022-03-27T12:06:34.609103Z","iopub.status.idle":"2022-03-27T12:06:34.624600Z","shell.execute_reply.started":"2022-03-27T12:06:34.609056Z","shell.execute_reply":"2022-03-27T12:06:34.623829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Q4. (3 points )\n\nWhy is BatchNormalisation layer important? Explain in atleast 50 words.\n","metadata":{"id":"XXMpD5fCxCX4"}},{"cell_type":"code","source":"# print your answer here\n\nexplanation = \"Increases the speed of training - In order to effectively learn with gradient descent we need a small learning rate to make sure we dont overshoot the minimum. Nomalization makes our cost function cotour plot more symmetric. We can use larger learning rates getting to the minumum faster. Allows sub optimal starts - in a loss function without batch normalization it might take us say about 100 iterations to get till convergence, if we start furthur out from minima, might take us say 1000 iterations. We cant define initialvalue of start since range is so large. But with new loss function with batch normalization we can randomly choose initialstart number between -1 to +1, no matter where we start, we can reach the minimum in similar number of iterations since contour plot is symmeticial (almost like a circle) so it helps make initial weights less important Acts a little like a regularizer - we can say Dropout as a regularizer which multiplies activation of neurons wit 0 and 1to randomly turn off neurons. with batch normalization there is an element of randomness as a batch is composed of randomsamples. we can still use batch normalization with dropout for better results\"\n\"\"\"\nIncreases the speed of training - In order to effectively learn with gradient descent we need a small learning \nrate to make sure we dont overshoot the minimum. Nomalization makes our cost function cotour plot more symmetric. \nWe can use larger learning rates getting to the minumum faster. \n\nAllows sub optimal starts - in a loss function without batch normalization it might take us say about 100 iterations \nto get till convergence, if we start furthur out from minima, might take us say 1000 iterations. We cant define initial\nvalue of start since range is so large. But with new loss function with batch normalization we can randomly choose initial\nstart number between -1 to +1, no matter where we start, we can reach the minimum in similar number of iterations since \ncontour plot is symmeticial (almost like a circle) so it helps make initial weights less important \n\nActs a little like a regularizer - we can say Dropout as a regularizer which multiplies activation of neurons wit 0 and 1\nto randomly turn off neurons. with batch normalization there is an element of randomness as a batch is composed of random\nsamples. we can still use batch normalization with dropout for better results\n\"\"\"\n\nprint(explanation)","metadata":{"id":"9KKfiODSxNdL","execution":{"iopub.status.busy":"2022-03-27T12:40:09.508601Z","iopub.execute_input":"2022-03-27T12:40:09.509041Z","iopub.status.idle":"2022-03-27T12:40:09.516730Z","shell.execute_reply.started":"2022-03-27T12:40:09.508987Z","shell.execute_reply":"2022-03-27T12:40:09.516008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Q5. (2 points)\n\nWhich of the following steps can be taken to prevent overfitting in a neural network?\n >A. Dropout of neurons\n\n >B. Early stopping\n\n >C. Batch normalization\n \n >D. All of the above\n\n Note: Read about Early Stopping here: https://keras.io/api/callbacks/early_stopping/","metadata":{"id":"EFw63_iQxYJD"}},{"cell_type":"code","source":"# print your answer here\n\nanswer = \"D\"\n\nprint(answer)","metadata":{"id":"TCLP8Zo1yKB4","execution":{"iopub.status.busy":"2022-03-27T12:41:29.665196Z","iopub.execute_input":"2022-03-27T12:41:29.665538Z","iopub.status.idle":"2022-03-27T12:41:29.670872Z","shell.execute_reply.started":"2022-03-27T12:41:29.665501Z","shell.execute_reply":"2022-03-27T12:41:29.669915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Q6. (10 Points)\n\n>Create function named cnn_model\n\n>Inside the function create a sequential model consisting of stack of Conv2D and MaxPooling2D layers.\n\n> Configure your CNN to process inputs of shape (32, 32, 3)\n\n> Use 'relu' as activation function\n\n> Flatten your 3D output to 1D\n\n> Add two Dense layers on top\n\n> Add a final Dense layer with 10 Outputs and 'softmax' activation function\n\n> Show your model summary\n\n> Finally compile your model using : \n\n\n*   adam optimizer\n*   sparse_categorical_crossentropy as the loss function\n*   metrics=[‘accuracy’]\n\n","metadata":{"id":"7JUbBopEyn-c"}},{"cell_type":"code","source":"# import necessary libraries\nimport tensorflow as tf\nfrom tensorflow.keras import datasets, layers, models","metadata":{"id":"1cjgFUEhy6Px","execution":{"iopub.status.busy":"2022-03-27T13:57:07.755924Z","iopub.execute_input":"2022-03-27T13:57:07.756946Z","iopub.status.idle":"2022-03-27T13:57:14.350736Z","shell.execute_reply.started":"2022-03-27T13:57:07.756898Z","shell.execute_reply":"2022-03-27T13:57:14.349847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# complete the below code\ndef cnn_model(): \n    cnn_model = tf.keras.Sequential([\n                tf.keras.layers.Conv2D(filters=24, kernel_size=(3,3), input_shape=(32, 32, 3), activation='relu'),        \n                tf.keras.layers.MaxPool2D(pool_size=(2,2)), \n                tf.keras.layers.Conv2D(24,(3,3),activation='relu'), #Defining the second convolutional layer\n                tf.keras.layers.MaxPool2D(strides=(2,2)), #Defining the second max pooling layer\n                #tf.keras.layers.Flatten(),\n                tf.keras.layers.Flatten(),\n                tf.keras.layers.Dense(128, activation='relu'),\n                tf.keras.layers.Dense(10,activation='softmax') #Defining the last Dense layer\n                                   ])\n    return cnn_model\n\n#print(cnn_model.output_shape)\n\n# build the model\ncnn_model = cnn_model()\n\n# show model summary\nprint(cnn_model.summary())\n\n# compile the model\ncnn_model.compile(optimizer='adam',\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\nprint(cnn_model.output_shape)","metadata":{"id":"kL3a5cVeyuet","execution":{"iopub.status.busy":"2022-03-27T13:57:19.499235Z","iopub.execute_input":"2022-03-27T13:57:19.499542Z","iopub.status.idle":"2022-03-27T13:57:19.668960Z","shell.execute_reply.started":"2022-03-27T13:57:19.499503Z","shell.execute_reply":"2022-03-27T13:57:19.668120Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Q7. (3 points)\n\nFor the model designed in Q6, calculate and print the total number of weights and biases.","metadata":{"id":"6XvB5GbIz8V9"}},{"cell_type":"code","source":"# print your answer here\n\ntotal_number_of_weights_and_biases = cnn_model.count_params()\n\nprint(total_number_of_weights_and_biases)\n\nnum_filters = 24\nfilter_size = 3\nnum_channels = 3\n\nweights_CONV2D_1 = (num_filters * filter_size * filter_size * num_channels)\nprint(\"Number of weights in layer CONV2D 1 is: \",weights_CONV2D_1)\n\nbiases_CONV2D_1 = num_filters\nprint(\"Number of biases in layer CONV2D 1 is: \",biases_CONV2D_1)\n\ntotal_parameters1 = weights_CONV2D_1 + biases_CONV2D_1\nprint(\"Total number of parameters in layer CONV2D 1 is: \",total_parameters1)\n\nnum_filters = 24\nfilter_size = 3\nnum_channels = 24\n\nweights_CONV2D_2 = (num_filters * filter_size * filter_size * num_channels)\nprint(\"Number of weights in layer CONV2D 2 is: \",weights_CONV2D_2)\n\nbiases_CONV2D_2 = num_filters\nprint(\"Number of biases in layer CONV2D 2 is: \",biases_CONV2D_2)\n\ntotal_parameters2 = weights_CONV2D_2 + biases_CONV2D_2\nprint(\"Total number of parameters in layer CONV2D 2 is: \",total_parameters2)\n\nf1 = 864\nf2 = 128\n\ndense_weight1 = (f1*f2)\nprint(\"Number of weights in dense layer 1 is: \",dense_weight1)\n\ndense_bias1 = f2\nprint(\"Number of biases in dense layer 1 is: \",dense_bias1)\n\ndense_parameters3 = (f1*f2) + f2\nprint(\"Total number of parameters in dense 1 layer: \",dense_parameters3)\n\nf1 = 128\nf2 = 10\n\ndense_weight2 = (f1*f2)\nprint(\"Number of weights in dense layer 2 is: \",dense_weight2)\n\ndense_bias2 = f2\nprint(\"Number of biases in dense layer 2 is: \",dense_bias2)\n\ndense_parameters4 = (f1*f2) + f2\nprint(\"Total number of parameters in dense 2 layer: \",dense_parameters4)\n\ntotal_weights_and_biases = total_parameters1 + total_parameters2 + dense_parameters3 + dense_parameters4\n\nprint(\"Total number of weights_and_biases in the network is: \",total_weights_and_biases)","metadata":{"id":"uvx-eckU0N_T","execution":{"iopub.status.busy":"2022-03-27T15:09:45.480698Z","iopub.execute_input":"2022-03-27T15:09:45.480990Z","iopub.status.idle":"2022-03-27T15:09:45.498160Z","shell.execute_reply.started":"2022-03-27T15:09:45.480958Z","shell.execute_reply":"2022-03-27T15:09:45.497119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Thank you for completing all the questions","metadata":{"id":"ZPJ95UaK0xeI"}}]}